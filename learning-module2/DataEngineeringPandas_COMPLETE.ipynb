{"cells":[{"cell_type":"markdown","metadata":{"id":"aDwn5eM3zIJW"},"source":["# Hands on - Applied data engineering with Pandas"]},{"cell_type":"markdown","metadata":{"id":"pAKh9GFq0oZc"},"source":["### ...or creating a simple ETL process"]},{"cell_type":"markdown","metadata":{"id":"aOSDvDxozHiv"},"source":["In this hands-on session, we will again work with the data from the ACM case. However, in the last module some data scientists have already invested some time in data engineering and wrangling.\n","\n","Given our newly gained pandas skills, we now want to follow their path...\n"]},{"cell_type":"markdown","metadata":{"id":"Yu2NygGrzjMJ"},"source":["# 1) Importing Files"]},{"cell_type":"markdown","metadata":{"id":"EQ5cONJbzn-B"},"source":["Import the survey data into pandas. However, the survey data is stored in three different sheets in the data file (\"2019\", \"2020\", and \"2021\"). Load them into pandas.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YGIK3z456lzj"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-meGRa_e0VJs"},"outputs":[],"source":["survey2019 = pd.read_excel(\"https://github.com/casbdai/notebooks2023/raw/main/Module2/DataEngineeringPandas/Pandas_TV_Survey_Data.xlsx\", sheet_name=\"2019\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OAe8SgQ00ZJ8"},"outputs":[],"source":["survey2020 = pd.read_excel(\"https://github.com/casbdai/notebooks2023/raw/main/Module2/DataEngineeringPandas/Pandas_TV_Survey_Data.xlsx\", sheet_name=\"2020\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZjUBmEsF5z6S"},"outputs":[],"source":["survey2021 = pd.read_excel(\"https://github.com/casbdai/notebooks2023/raw/main/Module2/DataEngineeringPandas/Pandas_TV_Survey_Data.xlsx\", sheet_name=\"2021\")"]},{"cell_type":"markdown","metadata":{"id":"YPbYaYC054lp"},"source":["Have a look at the three dataframes. They all have the same sructure and identical variable names. Paste theme together into a new dataframe."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JJrLJQmSPXcX"},"outputs":[],"source":["survey2019.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7FxqIqMx53Xp"},"outputs":[],"source":["survey2019.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MBP9KksKARiZ"},"outputs":[],"source":["survey2020.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQjvlRUnAXWI"},"outputs":[],"source":["survey2021.info()"]},{"cell_type":"markdown","metadata":{"id":"4XxF9uG1zImM"},"source":["Combine files row-wise or column-wise\n","\n","*   set **axis=0** to row-wise combination\n","*   set **axis=1** to row-wise combination"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yAig3f0S6uAz"},"outputs":[],"source":["survey = pd.concat([survey2019, survey2020, survey2021], axis = 0)\n","survey.info()"]},{"cell_type":"markdown","metadata":{"id":"RC8m3K3f6X57"},"source":["Now also read in the intentionality results using an appropriate reading function. Watch out for the delimeter!\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oNAD1ZhhCNyB"},"outputs":[],"source":["intentionality = pd.read_csv(\"https://raw.githubusercontent.com/casbdai/notebooks2023/main/Module2/DataEngineeringPandas/Pandas_TV_Intentionality_Data.csv\", sep=\";\")\n","intentionality.info()"]},{"cell_type":"markdown","metadata":{"id":"KjzZ81ouEmub"},"source":["We need to fix the variable type of \"date\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WCEoTk1HER_q"},"outputs":[],"source":["intentionality.date = pd.to_datetime(intentionality.date)\n","intentionality.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T5OxSvh7OW5l"},"outputs":[],"source":["gtrends = pd.read_excel(\"https://github.com/casbdai/notebooks2023/raw/main/Module2/DataEngineeringPandas/Pandas_TV_GTrends_Data.xlsx\")\n","gtrends.info()"]},{"cell_type":"markdown","metadata":{"id":"Qt7cWGcv6xSL"},"source":["# 2) Merging Files"]},{"cell_type":"markdown","metadata":{"id":"cnqstDis62ks"},"source":["Now after having loaded the data, we want to combine the data into one overarching data set. However, be aware that the data needs to be joined on three variables: Industry Ad Type, Program Name and date / Date Aired"]},{"cell_type":"markdown","metadata":{"id":"P7oYPqQt7AuJ"},"source":["Perform an inner join of the data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rxVl3_JZ7LP6"},"outputs":[],"source":["inner =  pd.merge(survey, intentionality,\n","                  how=\"inner\",\n","                  left_on=[\"IndustryAdType\", \"ProgramName\", \"DateAired\"],\n","                  right_on=[\"IndustryAdType\", \"ProgramName\", \"date\"])\n","\n","inner.info()"]},{"cell_type":"markdown","metadata":{"id":"LX8LGM9X76a2"},"source":["Perform an left join of the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DztglyDr8JXa"},"outputs":[],"source":["left =  pd.merge(survey, intentionality,\n","                  how=\"left\",\n","                  left_on=[\"IndustryAdType\", \"ProgramName\",\"DateAired\"],\n","                  right_on=[\"IndustryAdType\", \"ProgramName\",\"date\"])\n","\n","left.info()"]},{"cell_type":"markdown","metadata":{"id":"Kk1FNbf68Mz7"},"source":["How many NaNs are introduced in the variable intentionality? (you can use .info() )"]},{"cell_type":"markdown","metadata":{"id":"SOJyo27A8SmD"},"source":["Number of NaN: __"]},{"cell_type":"markdown","metadata":{"id":"Jbiv3Y8D8h9y"},"source":["Which joining method would you use for combining the two dataframe? Why?\n","\n","Your answer: __________________________"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LaHV70-SPOzG"},"outputs":[],"source":["left =  pd.merge(left, gtrends,\n","                  how=\"left\",\n","                  left_on=[\"IndustryAdType\", \"DateAired\"],\n","                  right_on=[\"IndustryAdType\", \"date\"])\n","\n","left.info()"]},{"cell_type":"markdown","metadata":{"id":"epHuZCfF8cty"},"source":["# 3) Dealing with NA"]},{"cell_type":"markdown","metadata":{"id":"7efJ9igX8sHy"},"source":["In order to practice our \"dealing with missing data skills\", we have to decided to go with an outer join."]},{"cell_type":"markdown","metadata":{"id":"jfddwdGE9QmB"},"source":["Create a new dataframe in which you have removed all missing values:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bjjA73ZP9Jdr"},"outputs":[],"source":["acmdata = left.dropna()\n","acmdata.info()"]},{"cell_type":"markdown","metadata":{"id":"DWWRpp5B9YxQ"},"source":["Create a new dataframe in which you insert 0 into the missing data fields of appropriate variables."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R1qEZLMQ9kWv"},"outputs":[],"source":["acmdata_0 = left.fillna(value=0)\n","acmdata_0.info()"]},{"cell_type":"markdown","metadata":{"id":"hJ3ddKFdHBLJ"},"source":["# 4) Tranforming Variables"]},{"cell_type":"markdown","metadata":{"id":"UyvN_6QaHP9J"},"source":["In the following exercises, we use the acmdata dataframe!"]},{"cell_type":"markdown","metadata":{"id":"JDFwR5yoHHm4"},"source":["Rename the variable \"Spend\" into \"Spend_in_000\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hv1chLAAHNeA"},"outputs":[],"source":["acmdata = acmdata.rename(columns={\"Spend\": \"Spend_in_000\"})\n","acmdata.info()"]},{"cell_type":"markdown","metadata":{"id":"7qvj-4Y3J5yh"},"source":["Delete the Variable \"date\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9prekiSVJ46p"},"outputs":[],"source":["del(acmdata[\"date_y\"])\n","acmdata.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NsiDqr621l7m"},"outputs":[],"source":["acmdata = acmdata.drop(\"date_x\", axis = 1)\n","acmdata.info()"]},{"cell_type":"markdown","metadata":{"id":"SrmVSsHOKSlw"},"source":["Aggregate the acmdata data frame by \"IndustryAdType\" using .mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H1MpspzkKYfb"},"outputs":[],"source":["acmdata.groupby(\"IndustryAdType\").mean()"]},{"cell_type":"markdown","metadata":{"id":"HSe7JbFJKwUh"},"source":["Aggregate the acm dataframe by \"Industry Ad Type\" and \"Program Name\" using .sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pFN5euA8LBfD"},"outputs":[],"source":["acmdata.groupby([\"IndustryAdType\", \"ProgramName\"]).sum()"]},{"cell_type":"markdown","metadata":{"id":"hVHJXQtZLAzn"},"source":["Again, aggregate the acmdata dataframe by \"Industry Ad Type\" and \"Program Name\" using .sum(). However, you are only interested in the \"Spend\" and \"Impressions\" data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4pG9CtTzLimQ"},"outputs":[],"source":["acmdata.groupby([\"IndustryAdType\", \"ProgramName\"])[[\"Spend_in_000\", \"Impressions\"]].sum()"]},{"cell_type":"markdown","metadata":{"id":"0DA1K2XAMN0D"},"source":["### Meaningful plots: Combining aggregations and .plot()"]},{"cell_type":"markdown","metadata":{"id":"5WHyxR3zMVt_"},"source":["For creating more meaningful and Tableau-like plots in python, you have to combine aggregations with the .plot() method"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NTT23iL8MNCW"},"outputs":[],"source":["acmdata.groupby([\"DateAired\"])[\"Spend_in_000\"].sum().plot()"]},{"cell_type":"markdown","metadata":{"id":"pI701HcKM9Dg"},"source":["a barplot of Spend by Program Name"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5_29EZj3NAHx"},"outputs":[],"source":["acmdata.groupby([\"ProgramName\"])[\"Spend_in_000\"].sum().plot(kind=\"bar\")"]},{"cell_type":"markdown","metadata":{"id":"TktHTgunNhiN"},"source":["# Writing Data File"]},{"cell_type":"markdown","metadata":{"id":"n-5tzqfRNj0-"},"source":["Now, write the merged and tidied data file as excel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JA3SSRGJQA8E"},"outputs":[],"source":["acmdata.to_excel(\"acmdata.xlsx\", index=False)"]},{"cell_type":"code","source":["from google.colab import files\n","files.download('acmdata.xlsx')"],"metadata":{"id":"MGNU6umByNXK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gib1oLjBINwm"},"source":["Or write the data into an SQL database"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y945WCTWITTX"},"outputs":[],"source":["import sqlalchemy as db\n","\n","engine = db.create_engine(\"sqlite:///cleaned_database\")\n","engine.connect()\n","\n","acmdata.to_sql('clean_acm_data', con=engine, if_exists=\"replace\", index=False)\n","\n","inspector = db.inspect(engine)\n","inspector.get_table_names()"]}],"metadata":{"colab":{"provenance":[{"file_id":"1h-Lnr6hfUB-SNsDhZ0op6cznod6OcnT1","timestamp":1578316099624}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}